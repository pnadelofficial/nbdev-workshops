# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_advanced_topic_modeling.ipynb.

# %% auto 0
__all__ = ['nlp', 'TopicModel', 'AdvancedTopicModel']

# %% ../nbs/03_advanced_topic_modeling.ipynb 3
# for tm
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.decomposition import LatentDirichletAllocation, NMF
import random

# for atm
from sentence_transformers import SentenceTransformer
import umap
import hdbscan
import collections
import spacy
nlp = spacy.load('en_core_web_sm')
from tqdm import tqdm
tqdm.pandas()
import re
import math
import pandas as pd
pd.options.plotting.backend = "plotly"
import numpy as np
from sklearn.cluster import KMeans
import plotly.express as px

# %% ../nbs/03_advanced_topic_modeling.ipynb 4
class TopicModel:
    "Models topics in a text given in the form of a list of sentences"
    def __init__(self, df, text_col, vectorizer, model, label_number=15):
        self.df = df 
        self.sentences = df[text_col].to_list()
        self.vectorizer = vectorizer
        self.model = model
        self.label_number = label_number
        
    def _vectorize_sentences(self):
        "Vectorizes text with vectorizer of choice"
        return self.vectorizer.fit_transform(self.sentences)
    
    def _get_topics(self, dtm):
        '''
        Iterates topics into a dictionary and
        modifies `DataFrame` to include a topic number for each text item in original `DataFrame`
        '''
        self.model.fit(dtm)
        topics_dict = {}
        for index, topic in enumerate(self.model.components_):
            topics_dict[f'Topic {index+1}'] = [self.vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-self.label_number:]]
        
        topic_results = self.model.transform(dtm)
        modified_df = self.df.copy()
        modified_df['Topic'] = topic_results.argmax(axis=1)+1
        
        return topics_dict, modified_df
    
    def model_topics(self):
        '''
        Runs all functions in correct sequence,
        returning modified `DataFrame` and a dictionary of topics with labels for further investigation
        '''
        print('vectorizing')
        dtm = self._vectorize_sentences()
        print('getting topics')
        topics_dict, modified_df = self._get_topics(dtm)
        
        return topics_dict, modified_df

# %% ../nbs/03_advanced_topic_modeling.ipynb 5
class AdvancedTopicModel:
    "Models topics in a text given in the form of a list of sentences"
    def __init__(self, sentences, model_name):
        self.model_name = model_name
        self.sentences = sentences
        self.model = SentenceTransformer(model_name)
        self.reducer = umap.UMAP()
        self.kmeans = KMeans(n_clusters=12, random_state=0)

    def _get_embeddings(self):
        "Encodes sentences using given model"
        return self.model.encode(self.sentences)

    def _get_reduced_embeddings(self, embeddings):
        "Reduces dimensions of word embeddings"
        return self.reducer.fit_transform(embeddings)

    def _create_df(self, new_embeddings):
        "Creates a DataFrame to hold reduced dimensionality"
        df = pd.DataFrame({"text": self.sentences})
        df['x'] = new_embeddings[:, 0]
        df['y'] = new_embeddings[:, 1]
        return df

    def _cluster(self, df):
        "Using HDBSCAN to cluster reduced embeddings"
        embed_from_df = list(zip(df['x'].to_list(), df['y'].to_list()))
        clusterer = hdbscan.HDBSCAN(min_cluster_size=30, min_samples=1, cluster_selection_epsilon=.01, cluster_selection_method='leaf', prediction_data=True).fit(embed_from_df)
        soft_clusters = hdbscan.all_points_membership_vectors(clusterer)

        df['labels'] = [np.argmax(x) for x in soft_clusters]
        return df

    def _is_stop_span(self, span):
        "Checks if a span contains a stop word"
        doc = span.as_doc()
        bools = [token.is_stop for token in doc]
        
        if any(bools):
            return True
        else:
            return False

    def _create_labels(self, df):
        "Creates labels for topics using `spaCy` noun chunking"
        series_dict = {}

        label_list = list(set(df.labels.unique()))
        for label in tqdm(label_list): 
            spacy_docs = df.loc[df.labels == label].text.apply(nlp)
            flat = [y for x in spacy_docs.apply(lambda x: [re.sub('[^\w]','',chunk.text.lower()) for chunk in x.noun_chunks if not self._is_stop_span(chunk)]).to_list() for y in x]
            freq = collections.defaultdict(int)
            for token in flat:
                freq[token] += 1
            freq = dict(freq)
            tf = dict(sorted(freq.items(), key=lambda item: item[1], reverse=True))

            idf = collections.defaultdict(int)
            for term in tf:
                for doc in spacy_docs:
                    if term in doc.text.lower():    
                        idf[term] += 1
            idf = dict(idf)
            idf = dict(sorted(idf.items(), key=lambda item: item[1], reverse=True))

            tfidf_dict = {}
            for term, f in idf.items():
                if tf[term] > 1:
                    tfidf_dict[term] = tf[term]*(math.log(len(spacy_docs)-f/f)+1) #smooth idf

            tfidf_dict = dict(sorted(tfidf_dict.items(), key=lambda item: item[1], reverse=True)[:5])

            key_string = ''
            for i, term in enumerate(tfidf_dict):
                if i < len(tfidf_dict)-1:
                    key_string += f'{term}; '
                else:
                    key_string += f'{term}'
            series_dict[f'label: {int(label)}'] = key_string

        return pd.DataFrame.from_dict(series_dict, orient='index')

    def _mean_embedding_cluster(self, label_df, df, embeddings):
        "Takes mean embeddings for each cluster"
        label_df = label_df.reset_index().rename(columns={'index':'label'})
        label_df['index_label'] = label_df['label'].apply(lambda x: int(x.split(': ')[1]))

        label_df = label_df.sort_values('index_label')
        label_df = label_df.drop('index_label', axis=1)

        label_df = label_df.rename(columns={'index':'label', 0:'rep_words'}).reset_index(drop=True)
        label_df['sents_indices'] = label_df['label'].apply(lambda x: df.loc[df.labels == int(x.split(': ')[1])].index)
        label_df['mean_embedding'] = label_df.sents_indices.apply(lambda x: np.mean(embeddings[x],axis=0))

        umap_mean_embeddings = self.reducer.fit_transform(label_df.mean_embedding.to_list())
        label_df['umap_mean_embeddings'] = list(umap_mean_embeddings)
        label_df['sent_amount'] = label_df['sents_indices'].apply(lambda x: len(x))
        label_df['x'] = label_df['umap_mean_embeddings'].apply(lambda x: x[0])
        label_df['y'] = label_df['umap_mean_embeddings'].apply(lambda x: x[1])

        return label_df, umap_mean_embeddings

    def _kmean_cluster(self, label_df, umap_mean_embeddings):
        "Uses KMeans clustering to cluster mean embeddings"
        kmeans = self.kmeans.fit(umap_mean_embeddings)
        label_df['kmeans'] = kmeans.labels_

        return label_df

    def show_plot(self, label_df):
        "Plots mean embeddings with `spaCy` labels"
        #fig = label_df.plot.scatter(x='x', y='y', size='sent_amount', color="kmeans", hover_data=['rep_words', 'label']) not sure why this doesnt work...
        fig = px.scatter(label_df, x='x', y='y',size='sent_amount',color='kmeans', hover_data=['rep_words', 'label'])
        fig.show()

    def model_topics(self):
        '''
        Runs all functions in correct sequence,
        plotting the topic model and
        returning labeled and original DataFrames for further investigation
        '''
        print(f'predicting embeddings from {self.model_name}')
        embeddings = self._get_embeddings()
        print('reducing embedding dimensions')
        reduced_embeddings = self._get_reduced_embeddings(embeddings)

        df = self._create_df(reduced_embeddings)
        df = self._cluster(df)

        print('creating topic labels')
        label_df = self._create_labels(df)
        print('reducing mean topic embedding')
        label_df, umap_mean_embeddings = self._mean_embedding_cluster(label_df, df, embeddings)
        print('clustering mean embeddings')
        label_df = self._kmean_cluster(label_df, umap_mean_embeddings)

        self.show_plot(label_df)
        return label_df, df
